{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "# Sales Data Cleaning - CP610 Deliverable #2\n\n**Purpose**: Clean and prepare sales transaction data for analysis  \n**Input**: `../datasources/Sales_v4.csv`  \n**Output**: `../output_data/Sales_cleaned.csv`  \n**Strategy**: See `../CLEANING_STRATEGY.md` for detailed methodology\n\n**Key Cleaning Approach**: **Transaction_ID + Date Composite Key**\n- 339 duplicate Transaction IDs resolved by creating composite key: Transaction_ID + Date\n- Original Transaction ID preserved in `Original_Transaction_ID` column\n- All 25,000 transactions retained with 100% unique identifiers (no artificial suffixes needed)\n- Semantically meaningful: reflects business reality that Transaction IDs are unique within a date\n\n---\n\n## Table of Contents\n1. [Load & Initial Exploration](#1)\n2. [Critical Issue: Duplicate Transaction IDs](#2)\n3. [Data Quality Assessment](#3)\n4. [Data Cleaning Operations](#4)\n5. [Feature Engineering](#5)\n6. [Data Validation](#6)\n7. [Export Cleaned Data](#7)\n8. [Comprehensive Quality Report](#8)"
  },
  {
   "cell_type": "markdown",
   "id": "clj0lajvx3",
   "source": "---\n## 1. Load & Initial Exploration",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "juz447xoaaf",
   "source": "# Import required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport os\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\n\n# Load sales data\ndf = pd.read_csv('../datasources/Sales_v4.csv')\n\nprint(\"=\"*60)\nprint(\"SALES DATA LOADED\")\nprint(\"=\"*60)\nprint(f\"Dataset shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\nprint(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\nprint(\"=\"*60)\n\n# Display info and sample\nprint(\"\\nDataset Info:\")\ndf.info()\nprint(\"\\nFirst 10 rows:\")\ndisplay(df.head(10))\nprint(\"\\nSummary Statistics:\")\ndisplay(df.describe())",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:46:12.867062Z",
     "start_time": "2025-10-25T02:46:12.799069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SALES DATA LOADED\n",
      "============================================================\n",
      "Dataset shape: 25,000 rows × 13 columns\n",
      "Memory usage: 12.24 MB\n",
      "============================================================\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Transaction ID      25000 non-null  object \n",
      " 1   Customer ID         25000 non-null  object \n",
      " 2   Location            25000 non-null  object \n",
      " 3   Payment Method      25000 non-null  object \n",
      " 4   Category            25000 non-null  object \n",
      " 5   Item                25000 non-null  object \n",
      " 6   Quantity            25000 non-null  int64  \n",
      " 7   Unit Price          25000 non-null  float64\n",
      " 8   Unit_Cost           25000 non-null  float64\n",
      " 9   Pre_Discount_Total  25000 non-null  float64\n",
      " 10  Discount_Rate       25000 non-null  float64\n",
      " 11  Total Spent         25000 non-null  float64\n",
      " 12  Date                25000 non-null  object \n",
      "dtypes: float64(5), int64(1), object(7)\n",
      "memory usage: 2.5+ MB\n",
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  Transaction ID Customer ID  Location  Payment Method   Category  \\\n",
       "0     TXN_490235   CUST_0175  In-store            Cash  Beverages   \n",
       "1     TXN_159495   CUST_0516    Online     Credit Card  Beverages   \n",
       "2     TXN_966263   CUST_0311  In-store            Cash  Beverages   \n",
       "3     TXN_703561   CUST_0322  In-store     Credit Card  Beverages   \n",
       "4     TXN_372997   CUST_0579  In-store     Credit Card  Beverages   \n",
       "5     TXN_158116   CUST_0135  In-store            Cash  Beverages   \n",
       "6     TXN_847823   CUST_0055    Online  Digital Wallet  Beverages   \n",
       "7     TXN_970778   CUST_0976  In-store            Cash  Beverages   \n",
       "8     TXN_902529   CUST_0543  In-store     Credit Card  Beverages   \n",
       "9     TXN_951291   CUST_0586  In-store     Credit Card  Beverages   \n",
       "\n",
       "            Item  Quantity  Unit Price  Unit_Cost  Pre_Discount_Total  \\\n",
       "0   Energy Drink        63        2.99       1.62              188.37   \n",
       "1  Bottled Water        38        1.05       0.55               39.90   \n",
       "2  Bottled Water        59        1.05       0.85               61.95   \n",
       "3       Tea Pack        50        2.86       1.83              143.00   \n",
       "4  Bottled Water        49        1.05       0.91               51.45   \n",
       "5   Energy Drink        12        2.99       2.15               35.88   \n",
       "6   Energy Drink        49        2.99       1.96              146.51   \n",
       "7   Energy Drink        41        2.99       1.58              122.59   \n",
       "8     Soft Drink        45        2.20       1.51               99.00   \n",
       "9   Energy Drink        31        2.99       1.83               92.69   \n",
       "\n",
       "   Discount_Rate  Total Spent        Date  \n",
       "0          0.044       180.08  2024-01-25  \n",
       "1          0.000        39.90  2024-12-27  \n",
       "2          0.000        61.95  2023-08-20  \n",
       "3          0.041       137.14  2025-08-20  \n",
       "4          0.000        51.45  2024-08-07  \n",
       "5          0.000        35.88  2023-09-04  \n",
       "6          0.033       141.68  2023-09-21  \n",
       "7          0.044       117.20  2025-08-15  \n",
       "8          0.000        99.00  2024-11-18  \n",
       "9          0.000        92.69  2024-12-02  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Category</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Unit_Cost</th>\n",
       "      <th>Pre_Discount_Total</th>\n",
       "      <th>Discount_Rate</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_490235</td>\n",
       "      <td>CUST_0175</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Energy Drink</td>\n",
       "      <td>63</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.62</td>\n",
       "      <td>188.37</td>\n",
       "      <td>0.044</td>\n",
       "      <td>180.08</td>\n",
       "      <td>2024-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_159495</td>\n",
       "      <td>CUST_0516</td>\n",
       "      <td>Online</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Bottled Water</td>\n",
       "      <td>38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.55</td>\n",
       "      <td>39.90</td>\n",
       "      <td>0.000</td>\n",
       "      <td>39.90</td>\n",
       "      <td>2024-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_966263</td>\n",
       "      <td>CUST_0311</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Bottled Water</td>\n",
       "      <td>59</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.85</td>\n",
       "      <td>61.95</td>\n",
       "      <td>0.000</td>\n",
       "      <td>61.95</td>\n",
       "      <td>2023-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_703561</td>\n",
       "      <td>CUST_0322</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Tea Pack</td>\n",
       "      <td>50</td>\n",
       "      <td>2.86</td>\n",
       "      <td>1.83</td>\n",
       "      <td>143.00</td>\n",
       "      <td>0.041</td>\n",
       "      <td>137.14</td>\n",
       "      <td>2025-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_372997</td>\n",
       "      <td>CUST_0579</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Bottled Water</td>\n",
       "      <td>49</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.91</td>\n",
       "      <td>51.45</td>\n",
       "      <td>0.000</td>\n",
       "      <td>51.45</td>\n",
       "      <td>2024-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TXN_158116</td>\n",
       "      <td>CUST_0135</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Energy Drink</td>\n",
       "      <td>12</td>\n",
       "      <td>2.99</td>\n",
       "      <td>2.15</td>\n",
       "      <td>35.88</td>\n",
       "      <td>0.000</td>\n",
       "      <td>35.88</td>\n",
       "      <td>2023-09-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TXN_847823</td>\n",
       "      <td>CUST_0055</td>\n",
       "      <td>Online</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Energy Drink</td>\n",
       "      <td>49</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.96</td>\n",
       "      <td>146.51</td>\n",
       "      <td>0.033</td>\n",
       "      <td>141.68</td>\n",
       "      <td>2023-09-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TXN_970778</td>\n",
       "      <td>CUST_0976</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Energy Drink</td>\n",
       "      <td>41</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.58</td>\n",
       "      <td>122.59</td>\n",
       "      <td>0.044</td>\n",
       "      <td>117.20</td>\n",
       "      <td>2025-08-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TXN_902529</td>\n",
       "      <td>CUST_0543</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Soft Drink</td>\n",
       "      <td>45</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.51</td>\n",
       "      <td>99.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>99.00</td>\n",
       "      <td>2024-11-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TXN_951291</td>\n",
       "      <td>CUST_0586</td>\n",
       "      <td>In-store</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Energy Drink</td>\n",
       "      <td>31</td>\n",
       "      <td>2.99</td>\n",
       "      <td>1.83</td>\n",
       "      <td>92.69</td>\n",
       "      <td>0.000</td>\n",
       "      <td>92.69</td>\n",
       "      <td>2024-12-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           Quantity    Unit Price     Unit_Cost  Pre_Discount_Total  \\\n",
       "count  25000.000000  25000.000000  25000.000000        25000.000000   \n",
       "mean      10.387760    159.926181    112.375159          553.573879   \n",
       "std       11.310347    437.743173    312.600882         1644.115697   \n",
       "min        1.000000      1.050000      0.530000            2.720000   \n",
       "25%        3.000000      5.160000      3.220000           42.675000   \n",
       "50%        7.000000     11.770000      8.105000           92.690000   \n",
       "75%       13.000000     53.610000     38.857500          254.700000   \n",
       "max      134.000000   2208.990000   1983.260000        29047.800000   \n",
       "\n",
       "       Discount_Rate   Total Spent  \n",
       "count   25000.000000  25000.000000  \n",
       "mean        0.027501    501.424512  \n",
       "std         0.034406   1434.715322  \n",
       "min         0.000000      2.720000  \n",
       "25%         0.000000     42.675000  \n",
       "50%         0.000000     92.690000  \n",
       "75%         0.046000    243.647500  \n",
       "max         0.187000  25039.200000  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Unit Price</th>\n",
       "      <th>Unit_Cost</th>\n",
       "      <th>Pre_Discount_Total</th>\n",
       "      <th>Discount_Rate</th>\n",
       "      <th>Total Spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "      <td>25000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.387760</td>\n",
       "      <td>159.926181</td>\n",
       "      <td>112.375159</td>\n",
       "      <td>553.573879</td>\n",
       "      <td>0.027501</td>\n",
       "      <td>501.424512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.310347</td>\n",
       "      <td>437.743173</td>\n",
       "      <td>312.600882</td>\n",
       "      <td>1644.115697</td>\n",
       "      <td>0.034406</td>\n",
       "      <td>1434.715322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>2.720000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.160000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>42.675000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.770000</td>\n",
       "      <td>8.105000</td>\n",
       "      <td>92.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>92.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>53.610000</td>\n",
       "      <td>38.857500</td>\n",
       "      <td>254.700000</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>243.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>134.000000</td>\n",
       "      <td>2208.990000</td>\n",
       "      <td>1983.260000</td>\n",
       "      <td>29047.800000</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>25039.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "2xfrg6j4z0t",
   "source": "---\n## 2. Critical Issue: Duplicate Transaction IDs  \n### Resolving Using Transaction_ID + Date Composite Key",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3kfdflkjnzn",
   "source": "# Step 1: Identify duplicate Transaction IDs and analyze patterns\nprint(\"=\"*60)\nprint(\"DUPLICATE TRANSACTION ID ANALYSIS\")\nprint(\"=\"*60)\n\ntotal_rows = len(df)\nunique_ids = df['Transaction ID'].nunique()\nduplicate_count = total_rows - unique_ids\n\nprint(f\"Total transactions: {total_rows:,}\")\nprint(f\"Unique Transaction IDs: {unique_ids:,}\")\nprint(f\"Duplicate Transaction IDs: {duplicate_count:,}\")\nprint(f\"Rows affected by duplicates: {df.duplicated(subset=['Transaction ID'], keep=False).sum():,}\")\n\n# Convert Date to datetime for composite key analysis\ndf['Date'] = pd.to_datetime(df['Date'])\n\n# Check if Transaction_ID + Date creates uniqueness\ndf['Date_Component'] = df['Date'].dt.strftime('%Y%m%d')\ndf['Transaction_ID_Date'] = df['Transaction ID'] + '_' + df['Date_Component']\nunique_composite = df['Transaction_ID_Date'].nunique()\n\nprint(f\"\\n🔍 Testing Transaction_ID + Date Composite Key:\")\nprint(f\"Unique Transaction_ID + Date combinations: {unique_composite:,}\")\nprint(f\"Achieves 100% uniqueness: {unique_composite == total_rows}\")\n\nif unique_composite == total_rows:\n    print(f\"✅ Transaction_ID + Date successfully resolves all {duplicate_count} duplicates!\")\n    print(f\"✅ No artificial suffixes needed - using natural composite key\")\nelse:\n    print(f\"⚠️ Still {total_rows - unique_composite} duplicates remaining\")\n\n# Store original Transaction ID for reference\ndf['Original_Transaction_ID'] = df['Transaction ID'].copy()\n\nprint(f\"\\nExample composite Transaction IDs:\")\nprint(df[['Original_Transaction_ID', 'Date', 'Transaction_ID_Date']].head(5).to_string(index=False))",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:46:15.015659Z",
     "start_time": "2025-10-25T02:46:14.955085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DUPLICATE TRANSACTION ID ANALYSIS\n",
      "============================================================\n",
      "Total transactions: 25,000\n",
      "Unique Transaction IDs: 24,661\n",
      "Duplicate Transaction IDs: 339\n",
      "Rows affected by duplicates: 673\n",
      "\n",
      "🔍 Testing Transaction_ID + Date Composite Key:\n",
      "Unique Transaction_ID + Date combinations: 25,000\n",
      "Achieves 100% uniqueness: True\n",
      "✅ Transaction_ID + Date successfully resolves all 339 duplicates!\n",
      "✅ No artificial suffixes needed - using natural composite key\n",
      "\n",
      "Example composite Transaction IDs:\n",
      "Original_Transaction_ID       Date Transaction_ID_Date\n",
      "             TXN_490235 2024-01-25 TXN_490235_20240125\n",
      "             TXN_159495 2024-12-27 TXN_159495_20241227\n",
      "             TXN_966263 2023-08-20 TXN_966263_20230820\n",
      "             TXN_703561 2025-08-20 TXN_703561_20250820\n",
      "             TXN_372997 2024-08-07 TXN_372997_20240807\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "tfah05kvzt",
   "source": "# Step 2: Apply Transaction_ID + Date composite key\nprint(\"=\"*60)\nprint(\"CREATING UNIQUE TRANSACTION IDs WITH DATE COMPOSITE KEY\")\nprint(\"=\"*60)\n\n# Replace Transaction ID with the composite key\ndf['Transaction ID'] = df['Transaction_ID_Date'].copy()\n\n# Verify uniqueness\nprint(f\"✅ All Transaction IDs are now unique: {df['Transaction ID'].is_unique}\")\nprint(f\"Total unique Transaction IDs: {df['Transaction ID'].nunique():,}\")\n\n# Show examples\nprint(\"\\n📋 Examples of new Transaction IDs:\")\nsample = df[['Original_Transaction_ID', 'Date', 'Transaction ID', 'Customer ID', 'Total Spent']].head(10)\ndisplay(sample)\n\nprint(\"\\n🔍 Approach Summary:\")\nprint(\"  • Original Transaction IDs preserved in 'Original_Transaction_ID' column\")\nprint(\"  • New Transaction ID format: TXN_XXXXXX_YYYYMMDD\")\nprint(\"  • Semantically meaningful: Transaction is unique within a date\")\nprint(\"  • No artificial suffixes needed (_1, _2, etc.)\")\nprint(\"  • 100% uniqueness achieved naturally\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:46:15.463860Z",
     "start_time": "2025-10-25T02:46:15.449185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CREATING UNIQUE TRANSACTION IDs WITH DATE COMPOSITE KEY\n",
      "============================================================\n",
      "✅ All Transaction IDs are now unique: True\n",
      "Total unique Transaction IDs: 25,000\n",
      "\n",
      "📋 Examples of new Transaction IDs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  Original_Transaction_ID       Date       Transaction ID Customer ID  \\\n",
       "0              TXN_490235 2024-01-25  TXN_490235_20240125   CUST_0175   \n",
       "1              TXN_159495 2024-12-27  TXN_159495_20241227   CUST_0516   \n",
       "2              TXN_966263 2023-08-20  TXN_966263_20230820   CUST_0311   \n",
       "3              TXN_703561 2025-08-20  TXN_703561_20250820   CUST_0322   \n",
       "4              TXN_372997 2024-08-07  TXN_372997_20240807   CUST_0579   \n",
       "5              TXN_158116 2023-09-04  TXN_158116_20230904   CUST_0135   \n",
       "6              TXN_847823 2023-09-21  TXN_847823_20230921   CUST_0055   \n",
       "7              TXN_970778 2025-08-15  TXN_970778_20250815   CUST_0976   \n",
       "8              TXN_902529 2024-11-18  TXN_902529_20241118   CUST_0543   \n",
       "9              TXN_951291 2024-12-02  TXN_951291_20241202   CUST_0586   \n",
       "\n",
       "   Total Spent  \n",
       "0       180.08  \n",
       "1        39.90  \n",
       "2        61.95  \n",
       "3       137.14  \n",
       "4        51.45  \n",
       "5        35.88  \n",
       "6       141.68  \n",
       "7       117.20  \n",
       "8        99.00  \n",
       "9        92.69  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Transaction_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Total Spent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_490235</td>\n",
       "      <td>2024-01-25</td>\n",
       "      <td>TXN_490235_20240125</td>\n",
       "      <td>CUST_0175</td>\n",
       "      <td>180.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_159495</td>\n",
       "      <td>2024-12-27</td>\n",
       "      <td>TXN_159495_20241227</td>\n",
       "      <td>CUST_0516</td>\n",
       "      <td>39.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_966263</td>\n",
       "      <td>2023-08-20</td>\n",
       "      <td>TXN_966263_20230820</td>\n",
       "      <td>CUST_0311</td>\n",
       "      <td>61.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_703561</td>\n",
       "      <td>2025-08-20</td>\n",
       "      <td>TXN_703561_20250820</td>\n",
       "      <td>CUST_0322</td>\n",
       "      <td>137.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_372997</td>\n",
       "      <td>2024-08-07</td>\n",
       "      <td>TXN_372997_20240807</td>\n",
       "      <td>CUST_0579</td>\n",
       "      <td>51.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TXN_158116</td>\n",
       "      <td>2023-09-04</td>\n",
       "      <td>TXN_158116_20230904</td>\n",
       "      <td>CUST_0135</td>\n",
       "      <td>35.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TXN_847823</td>\n",
       "      <td>2023-09-21</td>\n",
       "      <td>TXN_847823_20230921</td>\n",
       "      <td>CUST_0055</td>\n",
       "      <td>141.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TXN_970778</td>\n",
       "      <td>2025-08-15</td>\n",
       "      <td>TXN_970778_20250815</td>\n",
       "      <td>CUST_0976</td>\n",
       "      <td>117.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TXN_902529</td>\n",
       "      <td>2024-11-18</td>\n",
       "      <td>TXN_902529_20241118</td>\n",
       "      <td>CUST_0543</td>\n",
       "      <td>99.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TXN_951291</td>\n",
       "      <td>2024-12-02</td>\n",
       "      <td>TXN_951291_20241202</td>\n",
       "      <td>CUST_0586</td>\n",
       "      <td>92.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Approach Summary:\n",
      "  • Original Transaction IDs preserved in 'Original_Transaction_ID' column\n",
      "  • New Transaction ID format: TXN_XXXXXX_YYYYMMDD\n",
      "  • Semantically meaningful: Transaction is unique within a date\n",
      "  • No artificial suffixes needed (_1, _2, etc.)\n",
      "  • 100% uniqueness achieved naturally\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "jf69puq0x5b",
   "source": "---\n## 3. Data Quality Assessment",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "95mz45my5xq",
   "source": "# Data quality assessment\nTODAY = pd.Timestamp('2025-10-24')\ndf['has_future_date'] = df['Date'] > TODAY\n\n# Load cleaned customer data for validation\ncustomers = pd.read_csv('../output_data/Customers_cleaned.csv')\nvalid_customer_ids = set(customers['Customer ID'].unique())\ndf['has_invalid_customer'] = ~df['Customer ID'].isin(valid_customer_ids)\n\n# Check mathematical consistency\ndf['Expected_Pre_Discount'] = df['Quantity'] * df['Unit Price']\ndf['Pre_Discount_Error'] = abs(df['Pre_Discount_Total'] - df['Expected_Pre_Discount']) > 0.01\ndf['Expected_Total'] = df['Pre_Discount_Total'] * (1 - df['Discount_Rate'])\ndf['Total_Error'] = abs(df['Total Spent'] - df['Expected_Total']) > 0.01\n\n# Check for negative values and invalid discount rates\ndf['has_negative_qty'] = df['Quantity'] < 0\ndf['has_negative_price'] = df['Unit Price'] < 0\ndf['has_negative_cost'] = df['Unit_Cost'] < 0\ndf['has_negative_total'] = df['Total Spent'] < 0\ndf['invalid_discount'] = ~df['Discount_Rate'].between(0, 1)\n\n# Print quality assessment\nprint(\"=\"*60)\nprint(\"DATA QUALITY ASSESSMENT\")\nprint(\"=\"*60)\nprint(f\"Missing values: {df.isnull().sum().sum()}\")\nprint(f\"Future dates: {df['has_future_date'].sum()}\")\nprint(f\"Invalid Customer IDs: {df['has_invalid_customer'].sum()}\")\nprint(f\"Pre-discount errors: {df['Pre_Discount_Error'].sum()}\")\nprint(f\"Total calculation errors: {df['Total_Error'].sum()}\")\nprint(f\"Negative quantities: {df['has_negative_qty'].sum()}\")\nprint(f\"Negative prices: {df['has_negative_price'].sum()}\")\nprint(f\"Negative totals: {df['has_negative_total'].sum()}\")\nprint(f\"Invalid discount rates: {df['invalid_discount'].sum()}\")\nprint(\"=\"*60)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:46:16.901258Z",
     "start_time": "2025-10-25T02:46:16.884830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA QUALITY ASSESSMENT\n",
      "============================================================\n",
      "Missing values: 0\n",
      "Future dates: 111\n",
      "Invalid Customer IDs: 0\n",
      "Pre-discount errors: 0\n",
      "Total calculation errors: 0\n",
      "Negative quantities: 0\n",
      "Negative prices: 0\n",
      "Negative totals: 0\n",
      "Invalid discount rates: 0\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "86fs5zxzrwe",
   "source": "---\n## 4. Data Cleaning Operations",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "owrwqxkkwtd",
   "source": "# Create cleaned copy\ndf_clean = df.copy()\nprint(f\"Starting with {len(df_clean):,} rows\\n\")\n\n# Recalculate derived fields if errors found\nif df_clean['Pre_Discount_Error'].sum() > 0:\n    df_clean.loc[df_clean['Pre_Discount_Error'], 'Pre_Discount_Total'] = df_clean['Expected_Pre_Discount']\n    print(f\"✓ Fixed {df_clean['Pre_Discount_Error'].sum()} pre-discount calculation errors\")\n\nif df_clean['Total_Error'].sum() > 0:\n    df_clean.loc[df_clean['Total_Error'], 'Total Spent'] = df_clean['Expected_Total']\n    print(f\"✓ Fixed {df_clean['Total_Error'].sum()} total spent calculation errors\")\n\n# Round to 2 decimal places\ndf_clean['Pre_Discount_Total'] = df_clean['Pre_Discount_Total'].round(2)\ndf_clean['Total Spent'] = df_clean['Total Spent'].round(2)\n\n# Remove rows with critical errors (negative values)\nbefore = len(df_clean)\ndf_clean = df_clean[df_clean['Quantity'] > 0]\ndf_clean = df_clean[df_clean['Unit Price'] > 0]\ndf_clean = df_clean[df_clean['Total Spent'] >= 0]\nafter = len(df_clean)\nprint(f\"✓ Removed {before - after} rows with negative quantities/prices/totals\")\n\n# Standardize categorical fields\ndf_clean['Location'] = df_clean['Location'].str.strip().str.title()\ndf_clean['Payment Method'] = df_clean['Payment Method'].str.strip().str.title()\ndf_clean['Category'] = df_clean['Category'].str.strip().str.title()\ndf_clean['Item'] = df_clean['Item'].str.strip()\nprint(f\"✓ Standardized categorical fields\")\n\nprint(f\"\\nRows remaining: {len(df_clean):,}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:46:18.333130Z",
     "start_time": "2025-10-25T02:46:18.305648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 25,000 rows\n",
      "\n",
      "✓ Removed 0 rows with negative quantities/prices/totals\n",
      "✓ Standardized categorical fields\n",
      "\n",
      "Rows remaining: 25,000\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "j0mhin186o",
   "source": "---\n## 5. Feature Engineering",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "tlj1tmv0l7o",
   "source": "# Extract date components\ndf_clean['Year'] = df_clean['Date'].dt.year\ndf_clean['Month'] = df_clean['Date'].dt.month\ndf_clean['Day'] = df_clean['Date'].dt.day\ndf_clean['Day_of_Week'] = df_clean['Date'].dt.dayofweek\ndf_clean['Day_Name'] = df_clean['Date'].dt.day_name()\ndf_clean['Quarter'] = df_clean['Date'].dt.quarter\ndf_clean['Week_of_Year'] = df_clean['Date'].dt.isocalendar().week\n\n# Calculate profit metrics\ndf_clean['Profit_Per_Unit'] = df_clean['Unit Price'] - df_clean['Unit_Cost']\ndf_clean['Total_Profit'] = (df_clean['Profit_Per_Unit'] * df_clean['Quantity']).round(2)\ndf_clean['Profit_Margin'] = ((df_clean['Profit_Per_Unit'] / df_clean['Unit Price']) * 100).round(2)\n\n# Create data quality summary flag\ndef create_quality_flag(row):\n    flags = []\n    if row.get('has_future_date', False):\n        flags.append('FUTURE_DATE')\n    if row.get('has_invalid_customer', False):\n        flags.append('INVALID_CUSTOMER')\n    return '|'.join(flags) if flags else 'OK'\n\ndf_clean['data_quality_flag'] = df_clean.apply(create_quality_flag, axis=1)\n\nprint(\"=\"*60)\nprint(\"FEATURE ENGINEERING COMPLETE\")\nprint(\"=\"*60)\nprint(\"✓ Date components extracted (Year, Month, Day, Quarter, etc.)\")\nprint(\"✓ Profit metrics calculated (Profit Per Unit, Total Profit, Profit Margin)\")\nprint(\"✓ Data quality flags created\")\nprint(f\"\\nTotal columns: {len(df_clean.columns)}\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:46:19.221408Z",
     "start_time": "2025-10-25T02:46:19.117362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE ENGINEERING COMPLETE\n",
      "============================================================\n",
      "✓ Date components extracted (Year, Month, Day, Quarter, etc.)\n",
      "✓ Profit metrics calculated (Profit Per Unit, Total Profit, Profit Margin)\n",
      "✓ Data quality flags created\n",
      "\n",
      "Total columns: 38\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "66n61dpx5b8",
   "source": "---\n## 6. Data Validation",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "04l5lmwyxs4z",
   "source": "# Final validation checks\nprint(\"=\"*60)\nprint(\"FINAL VALIDATION CHECKS\")\nprint(\"=\"*60)\n\n# 1. Transaction ID uniqueness\nprint(f\"✓ Transaction IDs unique: {df_clean['Transaction ID'].is_unique}\")\n\n# 2. No missing critical fields\ncritical_fields = ['Transaction ID', 'Customer ID', 'Date', 'Total Spent']\nmissing = df_clean[critical_fields].isnull().sum().sum()\nprint(f\"✓ Missing values in critical fields: {missing}\")\n\n# 3. Date is datetime\nprint(f\"✓ Date column is datetime: {pd.api.types.is_datetime64_any_dtype(df_clean['Date'])}\")\n\n# 4. Positive values\nprint(f\"✓ All quantities positive: {(df_clean['Quantity'] > 0).all()}\")\nprint(f\"✓ All prices positive: {(df_clean['Unit Price'] > 0).all()}\")\nprint(f\"✓ All totals non-negative: {(df_clean['Total Spent'] >= 0).all()}\")\n\n# 5. Valid discount rates\nprint(f\"✓ All discount rates valid (0-1): {df_clean['Discount_Rate'].between(0, 1).all()}\")\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"✅ ALL VALIDATION CHECKS PASSED!\")\nprint(\"=\"*60)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:46:20.029343Z",
     "start_time": "2025-10-25T02:46:20.023373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL VALIDATION CHECKS\n",
      "============================================================\n",
      "✓ Transaction IDs unique: True\n",
      "✓ Missing values in critical fields: 0\n",
      "✓ Date column is datetime: True\n",
      "✓ All quantities positive: True\n",
      "✓ All prices positive: True\n",
      "✓ All totals non-negative: True\n",
      "✓ All discount rates valid (0-1): True\n",
      "\n",
      "============================================================\n",
      "✅ ALL VALIDATION CHECKS PASSED!\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "kd6ies2xq9",
   "source": "---\n## 7. Export Cleaned Data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "3bch6by1mqk",
   "source": "# Export cleaned data\nos.makedirs('../output_data', exist_ok=True)\noutput_file = '../output_data/Sales_cleaned.csv'\ndf_clean.to_csv(output_file, index=False)\n\nprint(\"=\"*60)\nprint(\"CLEANED DATA EXPORTED\")\nprint(\"=\"*60)\nprint(f\"Output file: {output_file}\")\nprint(f\"Rows exported: {len(df_clean):,}\")\nprint(f\"Columns: {len(df_clean.columns)}\")\nprint(\"=\"*60)",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:46:21.134603Z",
     "start_time": "2025-10-25T02:46:20.982589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLEANED DATA EXPORTED\n",
      "============================================================\n",
      "Output file: ../output_data/Sales_cleaned.csv\n",
      "Rows exported: 25,000\n",
      "Columns: 38\n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "9ed8cbha3oo",
   "source": "---\n## 8. Comprehensive Quality Report",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ufbx172l3v9",
   "source": "# Generate comprehensive quality report\nquality_report = {\n    'Dataset': 'Sales Data',\n    'Original_Rows': len(df),\n    'Cleaned_Rows': len(df_clean),\n    'Rows_Removed': len(df) - len(df_clean),\n    'Percentage_Retained': f\"{(len(df_clean) / len(df) * 100):.2f}%\",\n    'Original_Unique_Transaction_IDs': df['Original_Transaction_ID'].nunique(),\n    'Duplicate_Transaction_IDs_Found': len(df) - df['Original_Transaction_ID'].nunique(),\n    'Resolution_Method': 'Transaction_ID + Date Composite Key',\n    'Final_Unique_Transaction_IDs': df_clean['Transaction ID'].nunique(),\n    'Uniqueness_Achieved': '100% (Natural Composite Key)',\n    'Transactions_With_Future_Dates': df['has_future_date'].sum(),\n    'Date_Range': f\"{df_clean['Date'].min()} to {df_clean['Date'].max()}\",\n    'Transactions_With_Invalid_Customer_IDs': df['has_invalid_customer'].sum(),\n    'Missing_Values_Original': df.isnull().sum().sum(),\n    'Missing_Values_Cleaned': df_clean.isnull().sum().sum(),\n    'Pre_Discount_Calculation_Errors': df['Pre_Discount_Error'].sum(),\n    'Total_Calculation_Errors': df['Total_Error'].sum(),\n    'Total_Transactions': len(df_clean),\n    'Unique_Customers': df_clean['Customer ID'].nunique(),\n    'Total_Revenue': f\"${df_clean['Total Spent'].sum():,.2f}\",\n    'Total_Profit': f\"${df_clean['Total_Profit'].sum():,.2f}\",\n    'Average_Transaction_Value': f\"${df_clean['Total Spent'].mean():.2f}\",\n    'Average_Profit_Margin': f\"{df_clean['Profit_Margin'].mean():.2f}%\"\n}\n\n# Print report\nprint(\"\\n\" + \"=\"*60)\nprint(\"SALES DATA QUALITY REPORT\")\nprint(\"=\"*60)\nfor key, value in quality_report.items():\n    print(f\"{key}: {value}\")\nprint(\"=\"*60)\n\n# Save report to file\nreport_file = '../output_data/Sales_Quality_Report.txt'\nwith open(report_file, 'w') as f:\n    f.write(\"SALES DATA QUALITY REPORT\\n\")\n    f.write(\"=\"*60 + \"\\n\\n\")\n    for key, value in quality_report.items():\n        f.write(f\"{key}: {value}\\n\")\n    f.write(\"\\n\" + \"=\"*60 + \"\\n\")\n    f.write(\"\\nCleaning completed successfully!\\n\")\n    f.write(\"Cleaned data available at: output_data/Sales_cleaned.csv\\n\")\n\nprint(f\"\\n✅ Quality report saved to: {report_file}\")\nprint(\"\\n🎉 SALES DATA CLEANING COMPLETE!\")",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:46:22.059731Z",
     "start_time": "2025-10-25T02:46:22.040332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SALES DATA QUALITY REPORT\n",
      "============================================================\n",
      "Dataset: Sales Data\n",
      "Original_Rows: 25000\n",
      "Cleaned_Rows: 25000\n",
      "Rows_Removed: 0\n",
      "Percentage_Retained: 100.00%\n",
      "Original_Unique_Transaction_IDs: 24661\n",
      "Duplicate_Transaction_IDs_Found: 339\n",
      "Resolution_Method: Transaction_ID + Date Composite Key\n",
      "Final_Unique_Transaction_IDs: 25000\n",
      "Uniqueness_Achieved: 100% (Natural Composite Key)\n",
      "Transactions_With_Future_Dates: 111\n",
      "Date_Range: 2023-01-01 00:00:00 to 2025-10-28 00:00:00\n",
      "Transactions_With_Invalid_Customer_IDs: 0\n",
      "Missing_Values_Original: 0\n",
      "Missing_Values_Cleaned: 0\n",
      "Pre_Discount_Calculation_Errors: 0\n",
      "Total_Calculation_Errors: 0\n",
      "Total_Transactions: 25000\n",
      "Unique_Customers: 1000\n",
      "Total_Revenue: $12,535,612.80\n",
      "Total_Profit: $4,094,554.28\n",
      "Average_Transaction_Value: $501.42\n",
      "Average_Profit_Margin: 29.83%\n",
      "============================================================\n",
      "\n",
      "✅ Quality report saved to: ../output_data/Sales_Quality_Report.txt\n",
      "\n",
      "🎉 SALES DATA CLEANING COMPLETE!\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-25T02:46:22.791947Z",
     "start_time": "2025-10-25T02:46:22.790561Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "65ed6928c5a5e490",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ca1c7dc8c80a29bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
